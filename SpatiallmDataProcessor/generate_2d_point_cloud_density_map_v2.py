import numpy as np
import cv2
import open3d as o3d
import glob
import os
import re
import pandas as pd
from collections import defaultdict
import logging

# é…ç½®æ—¥å¿—ï¼šè¾“å‡ºåˆ°æ–‡ä»¶ï¼Œä»…è®°å½•å¿…è¦ä¿¡æ¯
logging.basicConfig(
    filename='.log',
    level=logging.DEBUG,
    format='%(asctime)s | %(levelname)s | %(name)s | %(message)s',
    filemode='w'
)
logging.getLogger('matplotlib').setLevel(logging.WARNING)
logging.getLogger('PIL').setLevel(logging.WARNING)


# ========== æ‚¨åŸæ¥çš„å‡½æ•°ï¼Œä¿æŒä¸å˜ ==========
def generate_2d_point_cloud_density_map(
    points,  # Nx2 or Nx3 numpy array, åªéœ€è¦ x,y
    output_png_path,
    target_size=(256, 256)
):
    if points.shape[1] == 3:
        points = points[:, :2]  # åªå– x, y

    min_xy = np.min(points, axis=0)
    max_xy = np.max(points, axis=0)
    range_xy = max_xy - min_xy

    max_xy = max_xy + 0.1 * range_xy  # æœ€å¤§å€¼å‘å¤–æ‰©å±•10%
    min_xy = min_xy - 0.1 * range_xy  # æœ€å°å€¼å‘å†…æ”¶ç¼©10%
    range_xy = max_xy - min_xy          # é‡æ–°è®¡ç®—æ‰©å±•åçš„èŒƒå›´

    eps = 1e-6
    range_xy = np.where(range_xy < eps, eps, range_xy)  # é¿å…é™¤ä»¥é›¶

    normalized_xy = (points - min_xy) / range_xy
    pixel_coords = (normalized_xy * (np.array(target_size) - 1)).astype(np.int32)

    density = np.zeros(target_size, dtype=np.float32)
    h, w = target_size

    valid = (
        (pixel_coords[:, 0] >= 0) & (pixel_coords[:, 0] < w) &
        (pixel_coords[:, 1] >= 0) & (pixel_coords[:, 1] < h)
    )
    valid_coords = pixel_coords[valid]
    unique_coords, counts = np.unique(valid_coords, axis=0, return_counts=True)

    density[unique_coords[:, 1], unique_coords[:, 0]] = counts  # y, x é¡ºåº

    density_normalized = density / (np.max(density) + 1e-6)
    density_uint8 = (density_normalized * 255).astype(np.uint8)
    cv2.imwrite(output_png_path, density_uint8)
    print(f"âœ… åˆå¹¶æˆ¿é—´å¯†åº¦å›¾å·²ä¿å­˜: {output_png_path}ï¼Œå°ºå¯¸: {density_uint8.shape}")
    return density_uint8

# ========== æ–°å¢ï¼šæ‰¹é‡å¤„ç†é€»è¾‘ ==========

def batch_generate_scene_density_maps(
    split_csv_path="split.csv",
    data_root="data",
    output_dir="output_density_maps",
    target_size=(256, 256)
):
    # 1. è¯»å– split.csv
    if not os.path.exists(split_csv_path):
        print(f"âŒ split.csv æ–‡ä»¶ä¸å­˜åœ¨: {split_csv_path}")
        logging.error(f"split.csv æ–‡ä»¶ä¸å­˜åœ¨: {split_csv_path}")
        return

    df = pd.read_csv(split_csv_path, sep=',', skipinitialspace=True)
    # å»é™¤å¯èƒ½çš„ç©ºç™½åˆ—åå’Œç©ºç™½æ•°æ®
    df.columns = [c.strip() for c in df.columns]
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

    # å–å‡ºæœ‰ç”¨çš„åˆ—ï¼Œç¡®ä¿å­—æ®µå­˜åœ¨
    required_columns = ['scene_id', 'chunk_id']
    for col in required_columns:
        if col not in df.columns:
            print(f"âŒ split.csv ä¸­ç¼ºå°‘å¿…è¦çš„åˆ—: {col}")
            logging.error(f"split.csv ä¸­ç¼ºå°‘å¿…è¦çš„åˆ—: {col}")
            return

    # æŒ‰ scene_id åˆ†ç»„ï¼Œå¾—åˆ°æ¯ä¸ª scene å¯¹åº”çš„ chunk_id åˆ—è¡¨
    scene_to_chunks = defaultdict(list)
    for _, row in df.iterrows():
        scene_id = row['scene_id']
        chunk_id = row['chunk_id']
        if pd.notna(scene_id) and pd.notna(chunk_id):
            scene_to_chunks[scene_id].append(chunk_id)

    # å»é‡
    for scene_id in scene_to_chunks:
        scene_to_chunks[scene_id] = list(set(scene_to_chunks[scene_id]))

    print(f"ğŸ” æ€»å…±å‘ç° {len(scene_to_chunks)} ä¸ª unique scene_id")
    logging.info(f"æ€»å…±å‘ç° {len(scene_to_chunks)} ä¸ª unique scene_id")

    # 2. å‡†å¤‡è¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # 3. éå†æ¯ä¸ª scene_id
    for scene_id, chunk_ids in scene_to_chunks.items():
        all_points = []  # æ”¶é›†è¯¥ scene ä¸‹æ‰€æœ‰ PLY çš„ x,y ç‚¹

        print(f"\nğŸ¯ æ­£åœ¨å¤„ç† scene_id: {scene_id}ï¼Œæ¥è‡ª chunk: {chunk_ids}")
        logging.info(f"æ­£åœ¨å¤„ç† scene_id: {scene_id}ï¼Œæ¥è‡ª chunk: {chunk_ids}")

        for chunk_id in chunk_ids:
            chunk_folder = os.path.join(data_root, f"chunk_{str(chunk_id).zfill(3)}")
            if not os.path.exists(chunk_folder):
                print(f"âš ï¸ chunk æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {chunk_folder}")
                logging.warning(f"chunk æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {chunk_folder}")
                continue

            # åŒ¹é…è¯¥ scene_id ä¸‹çš„æ‰€æœ‰ PLY æ–‡ä»¶: scene_{scene_id}_*.ply
            pattern = f"{scene_id}_*_0.ply"
            ply_files = glob.glob(os.path.join(chunk_folder, pattern))

            if not ply_files:
                print(f"âš ï¸ åœ¨ chunk {chunk_id} ä¸­æœªæ‰¾åˆ° scene_id={scene_id} çš„ PLY æ–‡ä»¶")
                logging.warning(f"åœ¨ chunk {chunk_id} ä¸­æœªæ‰¾åˆ° scene_id={scene_id} çš„ PLY æ–‡ä»¶")
                continue

            print(f"   ğŸ“‚ åœ¨ chunk {chunk_id} ä¸­æ‰¾åˆ° {len(ply_files)} ä¸ª PLY æ–‡ä»¶")
            logging.info(f"åœ¨ chunk {chunk_id} ä¸­æ‰¾åˆ° {len(ply_files)} ä¸ª PLY æ–‡ä»¶")

            for ply_path in ply_files:
                try:
                    pcd = o3d.io.read_point_cloud(ply_path)
                    if not pcd.has_points():
                        print(f"   âš ï¸ è·³è¿‡ç©ºç‚¹äº‘: {ply_path}")
                        logging.warning(f"è·³è¿‡ç©ºç‚¹äº‘: {ply_path}")
                        continue
                    points = np.asarray(pcd.points)  # Nx3
                    all_points.append(points[:, :2])  # åªè¦ x,y
                except Exception as e:
                    print(f"   âŒ è¯»å– PLY æ–‡ä»¶å¤±è´¥ {ply_path}: {e}")
                    logging.error(f"è¯»å– PLY æ–‡ä»¶å¤±è´¥ {ply_path}: {e}")
                    continue

        if not all_points:
            print(f"âŒ {scene_id} æ²¡æœ‰æœ‰æ•ˆçš„ç‚¹äº‘æ•°æ®")
            logging.error(f"{scene_id} æ²¡æœ‰æœ‰æ•ˆçš„ç‚¹äº‘æ•°æ®")
            continue

        all_points = np.vstack(all_points)  # åˆå¹¶æ‰€æœ‰ç‚¹

        # 4. ç”Ÿæˆå¯†åº¦å›¾
        output_png = os.path.join(output_dir, f"{scene_id}.png")
        generate_2d_point_cloud_density_map(all_points, output_png, target_size=target_size)
        print(f"   âœ… scene_id={scene_id} çš„å¯†åº¦å›¾å·²ä¿å­˜è‡³: {output_png}")
        logging.info(f"scene_id={scene_id} çš„å¯†åº¦å›¾å·²ä¿å­˜è‡³: {output_png}")

# ========== æ‰§è¡Œå…¥å£ ==========
if __name__ == "__main__":
    split_csv_path = "split_sample_0.csv"         # æ‚¨çš„ scene-chunk æ˜ å°„è¡¨
    data_root = "/mnt/data3/spatial_dataset/pcd"                   # æ•°æ®æ ¹ç›®å½•ï¼Œé‡Œé¢åŒ…å« chunk000, chunk001...
    output_dir = "output_density_maps"   # è¾“å‡ºå¯†åº¦å›¾ç›®å½•

    batch_generate_scene_density_maps(
        split_csv_path=split_csv_path,
        data_root=data_root,
        output_dir=output_dir,
        target_size=(256, 256)
    )